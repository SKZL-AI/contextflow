# ContextFlow Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider API Keys
# =============================================================================

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-...

# OpenAI
OPENAI_API_KEY=sk-...

# Google Gemini
GOOGLE_API_KEY=...

# Groq
GROQ_API_KEY=gsk_...

# Mistral
MISTRAL_API_KEY=...

# =============================================================================
# Local Provider Endpoints
# =============================================================================

# Ollama (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# vLLM (default: http://localhost:8000)
VLLM_BASE_URL=http://localhost:8000

# =============================================================================
# ContextFlow Settings
# =============================================================================

# Default provider (claude, openai, ollama, vllm, groq, gemini, mistral)
CONTEXTFLOW_DEFAULT_PROVIDER=claude

# Default model per provider
CONTEXTFLOW_CLAUDE_MODEL=claude-3-5-sonnet-20241022
CONTEXTFLOW_OPENAI_MODEL=gpt-4o
CONTEXTFLOW_OLLAMA_MODEL=llama2
CONTEXTFLOW_GROQ_MODEL=mixtral-8x7b-32768

# Strategy settings
CONTEXTFLOW_GSD_MAX_TOKENS=10000
CONTEXTFLOW_RALPH_MAX_TOKENS=100000
CONTEXTFLOW_RLM_MAX_PARALLEL_AGENTS=10
CONTEXTFLOW_RLM_MAX_ITERATIONS=50

# RAG settings
CONTEXTFLOW_EMBEDDING_PROVIDER=openai
CONTEXTFLOW_EMBEDDING_MODEL=text-embedding-3-small
CONTEXTFLOW_CHUNK_SIZE=4000
CONTEXTFLOW_CHUNK_OVERLAP=500

# =============================================================================
# API Server Settings
# =============================================================================

# Server configuration
CONTEXTFLOW_API_HOST=0.0.0.0
CONTEXTFLOW_API_PORT=8000
CONTEXTFLOW_API_KEY=your-api-key-here

# CORS (comma-separated origins)
CONTEXTFLOW_CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# =============================================================================
# Logging
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable JSON logging (for production)
LOG_JSON=false

# =============================================================================
# Telemetry (optional)
# =============================================================================

# Enable anonymous usage telemetry
CONTEXTFLOW_TELEMETRY_ENABLED=false
